{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5c424fc-3d80-44dd-88fe-6b59dac9c6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "target      0\n",
      "dtype: int64\n",
      "\n",
      "=====================================================\n",
      "\n",
      "target\n",
      "1    165\n",
      "0    138\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=====================================================\n",
      "\n",
      "\n",
      "=====================================================\n",
      "\n",
      "X_train.shape :  (242, 13)\n",
      "X_test.shape :  (61, 13)\n",
      "Y_train.shape :  (242,)\n",
      "Y_test.shape :  (61,)\n",
      "\n",
      "=====================================================\n",
      "\n",
      "Decision Tree Accuracy: 0.819672131147541\n",
      "\n",
      "Decision Tree Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.90      0.83        29\n",
      "           1       0.89      0.75      0.81        32\n",
      "\n",
      "    accuracy                           0.82        61\n",
      "   macro avg       0.83      0.82      0.82        61\n",
      "weighted avg       0.83      0.82      0.82        61\n",
      "\n",
      "DT Confusion Matrix:\n",
      " [[26  3]\n",
      " [ 8 24]]\n",
      "\n",
      "=====================================================\n",
      "\n",
      "Random Forest Accuracy: 0.8688524590163934\n",
      "\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.83      0.86        29\n",
      "           1       0.85      0.91      0.88        32\n",
      "\n",
      "    accuracy                           0.87        61\n",
      "   macro avg       0.87      0.87      0.87        61\n",
      "weighted avg       0.87      0.87      0.87        61\n",
      "\n",
      "RF Confusion Matrix:\n",
      " [[24  5]\n",
      " [ 3 29]]\n",
      "\n",
      "=====================================================\n",
      "\n",
      "SVM Accuracy: 0.8688524590163934\n",
      "\n",
      "SVM Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87        29\n",
      "           1       0.90      0.84      0.87        32\n",
      "\n",
      "    accuracy                           0.87        61\n",
      "   macro avg       0.87      0.87      0.87        61\n",
      "weighted avg       0.87      0.87      0.87        61\n",
      "\n",
      "SVM Confusion Matrix:\n",
      " [[26  3]\n",
      " [ 5 27]]\n",
      "\n",
      "=====================================================\n",
      "\n",
      "Logistic Regression Accuracy: 0.8524590163934426\n",
      "\n",
      "Logistic Regression Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.85        29\n",
      "           1       0.87      0.84      0.86        32\n",
      "\n",
      "    accuracy                           0.85        61\n",
      "   macro avg       0.85      0.85      0.85        61\n",
      "weighted avg       0.85      0.85      0.85        61\n",
      "\n",
      "LR Confusion Matrix:\n",
      " [[25  4]\n",
      " [ 5 27]]\n",
      "\n",
      "=====================================================\n",
      "\n",
      "KNN Accuracy: 0.9016393442622951\n",
      "\n",
      "KNN Algorithm Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90        29\n",
      "           1       0.93      0.88      0.90        32\n",
      "\n",
      "    accuracy                           0.90        61\n",
      "   macro avg       0.90      0.90      0.90        61\n",
      "weighted avg       0.90      0.90      0.90        61\n",
      "\n",
      "KNN Confusion Matrix:\n",
      " [[27  2]\n",
      " [ 4 28]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "file_path = \"https://github.com/MyungKyuYi/AI-class/raw/main/heart.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 결측치 확인\n",
    "print(df.isnull().sum())\n",
    "print(\"\\n=====================================================\\n\")\n",
    "\n",
    "# 레이블 불균형 여부를 위한 갯수 확인 (숫자)\n",
    "print(df['target'].value_counts())\n",
    "print(\"\\n=====================================================\\n\")\n",
    "\n",
    "\n",
    "# 모든 데이터들이 숫자이기 때문에 Encoding을 할 필요가 없다.\n",
    "\n",
    "# X와 Y 분할\n",
    "X = df.drop('target', axis=1) # Feature\n",
    "Y = df['target'] # Label\n",
    "\n",
    "# 학습 데이터 & 테스트 데이터 분할\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 데이터 표준화\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 분할된 데이터의 shape을 출력\n",
    "print(\"\\n=====================================================\\n\")\n",
    "print(\"X_train.shape : \", X_train.shape)\n",
    "print(\"X_test.shape : \", X_test.shape)\n",
    "print(\"Y_train.shape : \", Y_train.shape)\n",
    "print(\"Y_test.shape : \", Y_test.shape)\n",
    "\n",
    "\n",
    "# Decision Tree (DT)\n",
    "print(\"\\n=====================================================\\n\")\n",
    "dt_model = DecisionTreeClassifier() # DT 모델 생성.\n",
    "dt_model.fit(X_train, Y_train) # 모델 학습.\n",
    "dt_predictions = dt_model.predict(X_test) # 예측. 즉, dt_predictions에는 테스트 데이터 특성(X_test)에 따라 예측한 Y값이 들어있는 것.\n",
    "print(\"Decision Tree Accuracy:\", accuracy_score(Y_test, dt_predictions)) # 예측한 값과 실제 Y값을 비교하여 정확도 평가.\n",
    "print(\"\\nDecision Tree Classification Report:\\n\", classification_report(Y_test, dt_predictions))\n",
    "print(\"DT Confusion Matrix:\\n\", confusion_matrix(Y_test, dt_predictions)) # 혼동 행렬 출력\n",
    "\n",
    "# Random Forest (RF)\n",
    "print(\"\\n=====================================================\\n\")\n",
    "rf_model = RandomForestClassifier() # RF 모델 생성.\n",
    "rf_model.fit(X_train, Y_train) # 모델 학습.\n",
    "rf_predictions = rf_model.predict(X_test) # 예측. 즉, rf_predictions에는 테스트 데이터 특성(X_test)에 따라 예측한 Y값이 들어있는 것.\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(Y_test, rf_predictions)) # 예측한 값과 실제 Y값을 비교하여 정확도 평가.\n",
    "print(\"\\nRandom Forest Classification Report:\\n\", classification_report(Y_test, rf_predictions))\n",
    "print(\"RF Confusion Matrix:\\n\", confusion_matrix(Y_test, rf_predictions)) # 혼동 행렬 출력\n",
    "\n",
    "# Support Vector Machine (SVM)\n",
    "print(\"\\n=====================================================\\n\")\n",
    "svm_model = SVC() # SVM 모델 생성.\n",
    "svm_model.fit(X_train, Y_train) # 모델 학습.\n",
    "svm_predictions = svm_model.predict(X_test) # 예측. 즉, svm_predictions에는 테스트 데이터 특성(X_test)에 따라 예측한 Y값이 들어있는 것.\n",
    "print(\"SVM Accuracy:\", accuracy_score(Y_test, svm_predictions)) # 예측한 값과 실제 Y값을 비교하여 정확도 평가.\n",
    "print(\"\\nSVM Classification Report:\\n\", classification_report(Y_test, svm_predictions, zero_division=1))\n",
    "print(\"SVM Confusion Matrix:\\n\", confusion_matrix(Y_test, svm_predictions)) # 혼동 행렬 출력\n",
    "\n",
    "\n",
    "# Logistic Regression (LR)\n",
    "print(\"\\n=====================================================\\n\")\n",
    "lr_model = LogisticRegression() # LR 모델 생성.\n",
    "lr_model.fit(X_train, Y_train) # 모델 학습.\n",
    "lr_predictions = lr_model.predict(X_test) # 예측. 즉, lr_predictions에는 테스트 데이터 특성(X_test)에 따라 예측한 Y값이 들어있는 것.\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(Y_test, lr_predictions)) # 예측한 값과 실제 Y값을 비교하여 정확도 평가.\n",
    "print(\"\\nLogistic Regression Classification Report:\\n\", classification_report(Y_test, lr_predictions))\n",
    "print(\"LR Confusion Matrix:\\n\", confusion_matrix(Y_test, lr_predictions)) # 혼동 행렬 출력\n",
    "\n",
    "# K-Nearest Neighbors (KNN)\n",
    "print(\"\\n=====================================================\\n\")\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)  # 기본적으로 K=5 사용\n",
    "knn_model.fit(X_train, Y_train)\n",
    "knn_predictions = knn_model.predict(X_test)\n",
    "print(\"KNN Accuracy:\", accuracy_score(Y_test, knn_predictions))\n",
    "print(\"\\nKNN Algorithm Classification Report:\\n\", classification_report(Y_test, knn_predictions))\n",
    "print(\"KNN Confusion Matrix:\\n\", confusion_matrix(Y_test, knn_predictions)) # 혼동 행렬 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf5e820-261a-476e-9fcc-7f9bbdb8fcb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow_env)",
   "language": "python",
   "name": "tensorflow_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
