{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5fde0a9-f5ab-4d92-bcf6-65fb2dba91df",
   "metadata": {},
   "source": [
    "# Car_evaluation_classification\n",
    "\n",
    "## import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "961655dc-0cd9-4167-a102-7c781aa4b4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d1c53c-db2a-467e-8c75-7af14af13cb8",
   "metadata": {},
   "source": [
    "## Data Load & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a1e2559b-507a-4fa8-8dea-6502723a869c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0      1  2  3      4     5      6\n",
      "0  vhigh  vhigh  2  2  small   low  unacc\n",
      "1  vhigh  vhigh  2  2  small   med  unacc\n",
      "2  vhigh  vhigh  2  2  small  high  unacc\n",
      "3  vhigh  vhigh  2  2    med   low  unacc\n",
      "4  vhigh  vhigh  2  2    med   med  unacc\n",
      "\n",
      "=====================================================\n",
      "\n",
      "Index(['price', 'maint', 'doors', 'persons', 'lug_capacity', 'safety',\n",
      "       'output'],\n",
      "      dtype='object')\n",
      "\n",
      "=====================================================\n",
      "\n",
      "price           0\n",
      "maint           0\n",
      "doors           0\n",
      "persons         0\n",
      "lug_capacity    0\n",
      "safety          0\n",
      "output          0\n",
      "dtype: int64\n",
      "\n",
      "=====================================================\n",
      "\n",
      "output\n",
      "unacc    1210\n",
      "acc       384\n",
      "good       69\n",
      "vgood      65\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=====================================================\n",
      "\n",
      "output\n",
      "2    1210\n",
      "0     384\n",
      "1      69\n",
      "3      65\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=====================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:/Users/plo55/car_evaluation.csv\", header=None) # index_col = 0..?, # CSV 파일의 첫 번째 행(header)을 컬럼 이름으로 사용하지 않음\n",
    "# 파일에 헤더(컬럼 이름)가 없는 상태에서 header=None을 생략하면, 첫 번째 행이 컬럼 이름으로 사용됨(원래 데이터인데 헤더로 변함!).\n",
    "# 그래서 컬럼명을 직접 설정하려면 header=None을 넣어야 함!\n",
    "# index_col=0이면 첫 번째 열을 인덱스로 지정한다는 뜻이다. 하지만 car_evaluation.csv는 첫 번째 열이 데이터 값이므로 index_col=0을 사용하지 않는 게 맞다.\n",
    "print(df.head())\n",
    "print(\"\\n=====================================================\\n\")\n",
    "\n",
    "df.columns = ['price', 'maint', 'doors', 'persons', 'lug_capacity', 'safety', 'output'] # 각 컬럼명을 직접 지정\n",
    "# price: 가격, maint: 유지비, doors: 문 개수, persons: 수용 인원, lug_capacity: 트렁크 크기, safety: 안전성, output: 자동차 평가 결과 (label)\n",
    "print(df.columns) # 컬럼 확인 # print(df['output']) 특정 컬럼 확인\n",
    "print(\"\\n=====================================================\\n\")\n",
    "\n",
    "# 결측치 확인\n",
    "print(df.isnull().sum())\n",
    "print(\"\\n=====================================================\\n\")\n",
    "\n",
    "# 레이블 불균형 여부를 위한 갯수 확인 (숫자)\n",
    "print(df['output'].value_counts())\n",
    "print(\"\\n=====================================================\\n\")\n",
    "# output 불균형이 심한 것을 확인할 수 있다.\n",
    "# unacc    1210\n",
    "# acc       384\n",
    "# good       69\n",
    "# vgood      65\n",
    "# 이 경우 SMOTE를 이용해서 데이터를 증강하는 방법을 사용할 수 있다. 데이터가 적은 good과 vgood 클래스를 인위적으로 늘려서 학습을 해결하는 것.\n",
    "\n",
    "\n",
    "# 범주형 데이터를 숫자로 변환\n",
    "# 머신러닝 모델은 숫자 데이터를 입력으로 받기 때문에 범주형 데이터를 숫자로 변환해야 함.\n",
    "label_encoders = {} # 각 컬럼별 LabelEncoder 객체를 저장할 딕셔너리 생성\n",
    "columns = ['price', 'maint', 'doors', 'persons', 'lug_capacity', 'safety', 'output']\n",
    "for column in columns:\n",
    "  label_encoders[column] = LabelEncoder() # 해당 컬럼에 대해 LabelEncoder 객체 생성\n",
    "  df[column] = label_encoders[column].fit_transform(df[column]) # 데이터를 숫자로 변환\n",
    "\n",
    "# 레이블 갯수 확인 (숫자)\n",
    "print(df['output'].value_counts())\n",
    "print(\"\\n=====================================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c177da85-c353-4466-b79f-2c413c6b5110",
   "metadata": {},
   "source": [
    "## Data Preparation & Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9eb0fd27-62b1-4087-aa9b-ffdecae4efb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 3 0 0 2 1]\n",
      " [3 3 0 0 2 2]\n",
      " [3 3 0 0 2 0]\n",
      " ...\n",
      " [1 1 3 2 0 1]\n",
      " [1 1 3 2 0 2]\n",
      " [1 1 3 2 0 0]]\n",
      "[2 2 2 ... 2 1 3]\n",
      "\n",
      "=====================================================\n",
      "\n",
      "(1382, 6)\n",
      "(346, 6)\n",
      "(1382,)\n",
      "(346,)\n"
     ]
    }
   ],
   "source": [
    "# .values: 데이터프레임을 넘파이 배열로 변경함.\n",
    "X = df.drop('output', axis=1).values # Feature\n",
    "Y = df['output'].values # Label\n",
    "# DataFrame와 numpy 차이점\n",
    "# - numpy는 배열이므로 컬럼이 없음. 연산 속도가 더 빠른 대신 조작이 불편함.\n",
    "# - 반면에 df는 컬럼명이 있어서 데이터 조작이 편하지만 연산 속도가 느림.\n",
    "# - 그래서 데이터 분석 및 전처리를 df상태에서 하고 마지막에 numpy형식으로 변환하는 것.\n",
    "# 굳이 넘파이 배열로 바꾸어 주는 것을 명시하지 않아도 작동하기는 함!\n",
    "\n",
    "print(X)\n",
    "print(Y)\n",
    "\n",
    "# 학습 데이터 & 테스트 데이터 분할\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 데이터 표준화\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 분할된 데이터의 shape을 출력\n",
    "print(\"\\n=====================================================\\n\")\n",
    "print(X_train.shape) # (1382, 6) 6열짜리 데이터가 1382행 있다는 뜻.\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape) # (1382, ) 1열짜리 데이터가 1382행 있다는 뜻.\n",
    "print(Y_test.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa9ca56-11fc-41ba-bdb0-d70941ca6f34",
   "metadata": {},
   "source": [
    "## Train & Test & Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "019b8633-2afd-4591-871c-e7f0db6e7ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====================================================\n",
      "\n",
      "Decision Tree Accuracy: 0.9682080924855492\n",
      "\n",
      "Decision Tree Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94        83\n",
      "           1       0.56      0.91      0.69        11\n",
      "           2       1.00      1.00      1.00       235\n",
      "           3       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.97       346\n",
      "   macro avg       0.88      0.91      0.88       346\n",
      "weighted avg       0.98      0.97      0.97       346\n",
      "\n",
      "DT Confusion Matrix:\n",
      " [[ 76   6   1   0]\n",
      " [  1  10   0   0]\n",
      " [  0   0 235   0]\n",
      " [  1   2   0  14]]\n",
      "\n",
      "=====================================================\n",
      "\n",
      "Random Forest Accuracy: 0.9682080924855492\n",
      "\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.94        83\n",
      "           1       0.56      0.91      0.69        11\n",
      "           2       1.00      1.00      1.00       235\n",
      "           3       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.97       346\n",
      "   macro avg       0.87      0.94      0.89       346\n",
      "weighted avg       0.98      0.97      0.97       346\n",
      "\n",
      "RF Confusion Matrix:\n",
      " [[ 74   8   1   0]\n",
      " [  0  10   0   1]\n",
      " [  0   0 235   0]\n",
      " [  1   0   0  16]]\n",
      "\n",
      "=====================================================\n",
      "\n",
      "SVM Accuracy: 0.9017341040462428\n",
      "\n",
      "SVM Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80        83\n",
      "           1       0.44      0.36      0.40        11\n",
      "           2       0.96      0.96      0.96       235\n",
      "           3       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.90       346\n",
      "   macro avg       0.78      0.76      0.77       346\n",
      "weighted avg       0.90      0.90      0.90       346\n",
      "\n",
      "SVM Confusion Matrix:\n",
      " [[ 68   5  10   0]\n",
      " [  6   4   0   1]\n",
      " [ 10   0 225   0]\n",
      " [  2   0   0  15]]\n",
      "\n",
      "=====================================================\n",
      "\n",
      "Logistic Regression Accuracy: 0.6589595375722543\n",
      "\n",
      "Logistic Regression Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.13      0.18        83\n",
      "           1       1.00      0.00      0.00        11\n",
      "           2       0.72      0.92      0.81       235\n",
      "           3       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.66       346\n",
      "   macro avg       0.50      0.26      0.25       346\n",
      "weighted avg       0.59      0.66      0.59       346\n",
      "\n",
      "LR Confusion Matrix:\n",
      " [[ 11   0  69   3]\n",
      " [  2   0   9   0]\n",
      " [ 17   0 217   1]\n",
      " [ 12   0   5   0]]\n",
      "\n",
      "=====================================================\n",
      "\n",
      "KNN Accuracy: 0.9421965317919075\n",
      "\n",
      "KNN Algorithm Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88        83\n",
      "           1       1.00      0.64      0.78        11\n",
      "           2       0.97      1.00      0.98       235\n",
      "           3       0.92      0.65      0.76        17\n",
      "\n",
      "    accuracy                           0.94       346\n",
      "   macro avg       0.94      0.79      0.85       346\n",
      "weighted avg       0.94      0.94      0.94       346\n",
      "\n",
      "KNN Confusion Matrix:\n",
      " [[ 74   0   8   1]\n",
      " [  4   7   0   0]\n",
      " [  1   0 234   0]\n",
      " [  6   0   0  11]]\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree (DT)\n",
    "print(\"\\n=====================================================\\n\")\n",
    "dt_model = DecisionTreeClassifier() # DT 모델 생성.\n",
    "dt_model.fit(X_train, Y_train) # 모델 학습.\n",
    "dt_predictions = dt_model.predict(X_test) # 예측. 즉, dt_predictions에는 테스트 데이터 특성(X_test)에 따라 예측한 Y값이 들어있는 것.\n",
    "print(\"Decision Tree Accuracy:\", accuracy_score(Y_test, dt_predictions)) # 예측한 값과 실제 Y값을 비교하여 정확도 평가.\n",
    "print(\"\\nDecision Tree Classification Report:\\n\", classification_report(Y_test, dt_predictions, zero_division=1))\n",
    "print(\"DT Confusion Matrix:\\n\", confusion_matrix(Y_test, dt_predictions)) # 혼동 행렬 출력\n",
    "\n",
    "# Random Forest (RF)\n",
    "print(\"\\n=====================================================\\n\")\n",
    "rf_model = RandomForestClassifier() # RF 모델 생성.\n",
    "rf_model.fit(X_train, Y_train) # 모델 학습.\n",
    "rf_predictions = rf_model.predict(X_test) # 예측. 즉, rf_predictions에는 테스트 데이터 특성(X_test)에 따라 예측한 Y값이 들어있는 것.\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(Y_test, rf_predictions)) # 예측한 값과 실제 Y값을 비교하여 정확도 평가.\n",
    "print(\"\\nRandom Forest Classification Report:\\n\", classification_report(Y_test, rf_predictions, zero_division=1))\n",
    "print(\"RF Confusion Matrix:\\n\", confusion_matrix(Y_test, rf_predictions)) # 혼동 행렬 출력\n",
    "\n",
    "# Support Vector Machine (SVM)\n",
    "print(\"\\n=====================================================\\n\")\n",
    "svm_model = SVC() # SVM 모델 생성.\n",
    "svm_model.fit(X_train, Y_train) # 모델 학습.\n",
    "svm_predictions = svm_model.predict(X_test) # 예측. 즉, svm_predictions에는 테스트 데이터 특성(X_test)에 따라 예측한 Y값이 들어있는 것.\n",
    "print(\"SVM Accuracy:\", accuracy_score(Y_test, svm_predictions)) # 예측한 값과 실제 Y값을 비교하여 정확도 평가.\n",
    "print(\"\\nSVM Classification Report:\\n\", classification_report(Y_test, svm_predictions, zero_division=1))\n",
    "print(\"SVM Confusion Matrix:\\n\", confusion_matrix(Y_test, svm_predictions)) # 혼동 행렬 출력\n",
    "\n",
    "# Logistic Regression (LR)\n",
    "print(\"\\n=====================================================\\n\")\n",
    "lr_model = LogisticRegression() # LR 모델 생성.\n",
    "lr_model.fit(X_train, Y_train) # 모델 학습.\n",
    "lr_predictions = lr_model.predict(X_test) # 예측. 즉, lr_predictions에는 테스트 데이터 특성(X_test)에 따라 예측한 Y값이 들어있는 것.\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(Y_test, lr_predictions)) # 예측한 값과 실제 Y값을 비교하여 정확도 평가.\n",
    "print(\"\\nLogistic Regression Classification Report:\\n\", classification_report(Y_test, lr_predictions, zero_division=1))\n",
    "print(\"LR Confusion Matrix:\\n\", confusion_matrix(Y_test, lr_predictions)) # 혼동 행렬 출력\n",
    "# Logistic Regression은 클래스 불균형과 비선형 문제에 약한데, Car_evaluation의 경우 레이블 불균형이 심해서 모델 성능(예측 성공률)이 낮게 나온다.\n",
    "\n",
    "# K-Nearest Neighbors (KNN)\n",
    "print(\"\\n=====================================================\\n\")\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)  # 기본적으로 K=5 사용\n",
    "knn_model.fit(X_train, Y_train)\n",
    "knn_predictions = knn_model.predict(X_test)\n",
    "print(\"KNN Accuracy:\", accuracy_score(Y_test, knn_predictions))\n",
    "print(\"\\nKNN Algorithm Classification Report:\\n\", classification_report(Y_test, knn_predictions, zero_division=1))\n",
    "print(\"KNN Confusion Matrix:\\n\", confusion_matrix(Y_test, knn_predictions)) # 혼동 행렬 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5143d5aa-a53f-4809-a541-e6e8d6ef0272",
   "metadata": {},
   "source": [
    "## 혼동 행렬에 대하여\n",
    "\n",
    "혼동행렬\n",
    "- 실질적으로 어떤 클래스가 잘 예측됐는지 안됐는지 디테일하게 알기 위해서 사용.\n",
    "- 모델이 얼마나 정확하게 각 클래스를 예측했는지 시각적으로 확인할 수 있는 도구.\n",
    "  \n",
    "혼동행렬은 분류 모델의 성능을 평가하는 데 사용되는 표로, 실제 값과 모델이 예측한 값의 관계를 시각적으로 나타낸다. 각 행은 실제 클래스(진짜 클래스)를 나타내고, 각 열은 예측된 클래스(모델의 예측)를 나타낸다.\n",
    "\n",
    "혼동행렬은 보통 다음과 같은 형태로 나타낸다:\n",
    "\n",
    "|               | Predicted Class 0 | Predicted Class 1 | Predicted Class 2 | Predicted Class 3 |\n",
    "|---------------|--------------------|--------------------|--------------------|--------------------|\n",
    "| **True Class 0** | True Positive (TP)   | False Positive (FP)  | False Negative (FN) | False Negative (FN) |\n",
    "| **True Class 1** | False Positive (FP)  | True Positive (TP)   | False Negative (FN) | False Negative (FN) |\n",
    "| **True Class 2** | False Negative (FN)  | False Negative (FN)  | True Positive (TP)  | False Positive (FP) |\n",
    "| **True Class 3** | False Negative (FN)  | False Negative (FN)  | False Negative (FN) | True Positive (TP)  |\n",
    "\n",
    "예시\n",
    "SVM Confusion Matrix:\n",
    "\\\n",
    "\\begin{bmatrix}\n",
    "    68 & 5  & 10 & 0 \\\\ \n",
    "    6  & 4  & 0  & 1 \\\\\n",
    "    10 & 0  & 225 & 0 \\\\\n",
    "    2  & 0  & 0  & 15\n",
    "\\end{bmatrix}\n",
    "\n",
    " 첫번째 행: 실제 클래스 0에 대해 예측한 클래스들<br>\n",
    "  - 68: 실제 클래스 0인 데이터가 모델에 의해 정확히 클래스 0으로 예측된 수 (True Positive)\n",
    "  - 5: 실제 클래스 0인 데이터가 모델에 의해 잘못 클래스 1로 예측된 수 (False Positive)\n",
    "  - 10: 실제 클래스 0인 데이터가 모델에 의해 잘못 클래스 2로 예측된 수 (False Positive)\n",
    "  - 0: 실제 클래스 0인 데이터가 모델에 의해 잘못 클래스 3으로 예측된 수 (False Positive)<br>\n",
    "\n",
    " 두번째 행: 실제 클래스 1에 대해 예측한 클래스들<br>\n",
    "  - 6: 실제 클래스 1인 데이터가 모델에 의해 잘못 클래스 0으로 예측된 수 (False Negative)\n",
    "  - 4: 실제 클래스 1인 데이터가 모델에 의해 정확히 클래스 1로 예측된 수 (True Positive)\n",
    "  - 0: 실제 클래스 1인 데이터가 모델에 의해 잘못 클래스 2로 예측된 수 (False Positive)\n",
    "  - 1: 실제 클래스 1인 데이터가 모델에 의해 잘못 클래스 3으로 예측된 수 (False Positive)\n",
    "<br>\n",
    "\n",
    " 세번째 행: 실제 클래스 2에 대해 예측한 클래스들<br>\n",
    " 네번째 행: 실제 클래스 3에 대해 예측한 클래스들<br>\n",
    " \n",
    "여기서:\n",
    "- **True Positive (TP)**: 실제 양성 클래스이면서, 모델이 양성 클래스라고 예측한 경우\n",
    "- **False Positive (FP)**: 실제 음성 클래스이지만, 모델이 양성 클래스라고 잘못 예측한 경우\n",
    "- **False Negative (FN)**: 실제 양성 클래스이지만, 모델이 음성 클래스라고 잘못 예측한 경우\n",
    "- **True Negative (TN)**: 실제 음성 클래스이면서, 모델이 음성 클래스라고 예측한 경우\n",
    "\n",
    "## 혼동행렬의 지표\n",
    "\n",
    "혼동행렬을 통해 다양한 성능 지표를 계산할 수 있다. 대표적인 지표는 다음과 같다:\n",
    "\n",
    "- **정확도 (Accuracy)**: 모델이 얼마나 정확하게 예측했는지. Accuracy = (TP + TN) / (전체 데이터)\n",
    "- **정밀도 (Precision)**: 특정 클래스에 대해 얼마나 정확하게 예측했는지. Precision = TP / (TP + FP)\n",
    "- **재현율 (Recall)**: 실제 특정 클래스가 얼마나 잘 예측되었는지. Recall = TP / (TP + FN)\n",
    "- **F1 Score**: 정밀도와 재현율의 조화 평균. F1 Score = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e0c929-a3fd-4346-be0f-db3fff06e1d4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
